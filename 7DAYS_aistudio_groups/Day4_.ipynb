{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddleHub之《青春有你2》作业：五人识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、任务简介\n",
    "\n",
    "图像分类是计算机视觉的重要领域，它的目标是将图像分类到预定义的标签。近期，许多研究者提出很多不同种类的神经网络，并且极大的提升了分类算法的性能。本文以自己创建的数据集：青春有你2中选手识别为例子，介绍如何使用PaddleHub进行图像分类任务。\n",
    "\n",
    "<div  align=\"center\">   \n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/dbaf5ba718f749f0836c342fa67f6d7954cb89f3796b4c8b981a03a1635f2fbe\" width = \"350\" height = \"250\" align=center />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU环境启动请务必执行该指令\n",
    "# %set_env CPU_NUM=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlehub==1.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.6.0)\n",
      "Requirement already satisfied: yapf==0.26.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (0.26.0)\n",
      "Requirement already satisfied: chardet==3.0.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (3.0.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (6.2.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (5.1.2)\n",
      "Requirement already satisfied: pandas; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (0.23.4)\n",
      "Requirement already satisfied: numpy; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (1.16.4)\n",
      "Requirement already satisfied: tb-paddle in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (0.3.6)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (0.1.85)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (1.21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (1.12.0)\n",
      "Requirement already satisfied: cma==2.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (2.7.0)\n",
      "Requirement already satisfied: gunicorn>=19.10.0; sys_platform != \"win32\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (20.0.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (3.10.0)\n",
      "Requirement already satisfied: tensorboard>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (2.1.0)\n",
      "Requirement already satisfied: flake8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (3.7.9)\n",
      "Requirement already satisfied: flask>=1.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (1.1.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (4.1.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (3.4.5)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==1.6.0) (4.1.1.26)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas; python_version >= \"3\"->paddlehub==1.6.0) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas; python_version >= \"3\"->paddlehub==1.6.0) (2019.3)\n",
      "Requirement already satisfied: moviepy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tb-paddle->paddlehub==1.6.0) (1.0.1)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (0.10.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (1.4.10)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (0.23)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (1.3.4)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (1.3.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (2.0.1)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->paddlehub==1.6.0) (16.7.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddlehub==1.6.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddlehub==1.6.0) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->paddlehub==1.6.0) (2019.9.11)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gunicorn>=19.10.0; sys_platform != \"win32\"->paddlehub==1.6.0) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (3.1.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (0.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (0.4.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (0.33.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (1.10.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (1.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from tensorboard>=1.15->paddlehub==1.6.0) (0.16.0)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.6.0) (2.1.1)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.6.0) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.6.0) (2.5.0)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8->paddlehub==1.6.0) (0.3)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.6.0) (2.10.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.6.0) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.0->paddlehub==1.6.0) (7.0)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5; python_version >= \"3.4\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub==1.6.0) (2.6.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0; python_version >= \"3.4\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub==1.6.0) (0.3.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub==1.6.0) (0.1.9)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub==1.6.0) (4.4.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from moviepy->tb-paddle->paddlehub==1.6.0) (4.36.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->pre-commit->paddlehub==1.6.0) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->paddlehub==1.6.0) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub==1.6.0) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub==1.6.0) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub==1.6.0) (0.2.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.0->paddlehub==1.6.0) (1.1.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->pre-commit->paddlehub==1.6.0) (7.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->paddlehub==1.6.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard>=1.15->paddlehub==1.6.0) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "#安装paddlehub\n",
    "!pip install paddlehub==1.6.0 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、任务实践\n",
    "### Step1、基础工作\n",
    "\n",
    "加载数据文件\n",
    "\n",
    "导入python包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: ./dataset/zhaoxiaotang/99.jpg  \r"
     ]
    }
   ],
   "source": [
    "!unzip -o ./work/file.zip -d ./dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddlehub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2、加载预训练模型\n",
    "\n",
    "接下来我们要在PaddleHub中选择合适的预训练模型来Finetune，由于是图像分类任务，因此我们使用经典的ResNet-50作为预训练模型。PaddleHub提供了丰富的图像分类预训练模型，包括了最新的神经网络架构搜索类的PNASNet，我们推荐您尝试不同的预训练模型来获得更好的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-04-27 00:10:10,566] [    INFO] - Installing resnet_v2_50_imagenet module\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:10:10,645] [    INFO] - Module resnet_v2_50_imagenet already installed in /home/aistudio/.paddlehub/modules/resnet_v2_50_imagenet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "module = hub.Module(name=\"resnet_v2_50_imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3、数据准备\n",
    "\n",
    "接着需要加载图片数据集。我们使用自定义的数据进行体验，请查看[适配自定义数据](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub适配自定义数据完成FineTune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddlehub.dataset.base_cv_dataset import BaseCVDataset\n",
    "   \n",
    "class DemoDataset(BaseCVDataset):\n",
    "    def __init__(self):\n",
    "       # 数据集存放位置\n",
    "       \n",
    "        self.dataset_dir = \"./\"\n",
    "        super(DemoDataset, self).__init__(\n",
    "           base_path=self.dataset_dir,\n",
    "           train_list_file=\"dataset/train_list.txt\",\n",
    "           validate_list_file=\"dataset/validate_list.txt\",\n",
    "           test_list_file=\"dataset/test_list.txt\",\n",
    "           label_list_file=\"dataset/label_list.txt\",\n",
    "           )\n",
    "dataset = DemoDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4、生成数据读取器\n",
    "\n",
    "接着生成一个图像分类的reader，reader负责将dataset的数据进行预处理，接着以特定格式组织并输入给模型进行训练。\n",
    "\n",
    "当我们生成一个图像分类的reader时，需要指定输入图片的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-04-27 00:10:16,347] [    INFO] - Dataset label map = {'安崎': 0, '王承渲': 1, '许佳琪': 2, '虞书欣': 3, '赵小棠': 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_reader = hub.reader.ImageClassificationReader(\n",
    "    image_width=module.get_expected_image_width(),\n",
    "    image_height=module.get_expected_image_height(),\n",
    "    images_mean=module.get_pretrained_images_mean(),\n",
    "    images_std=module.get_pretrained_images_std(),\n",
    "    dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5、配置策略\n",
    "在进行Finetune前，我们可以设置一些运行时的配置，例如如下代码中的配置，表示：\n",
    "\n",
    "* `use_cuda`：设置为False表示使用CPU进行训练。如果您本机支持GPU，且安装的是GPU版本的PaddlePaddle，我们建议您将这个选项设置为True；\n",
    "\n",
    "* `epoch`：迭代轮数；\n",
    "\n",
    "* `batch_size`：每次训练的时候，给模型输入的每批数据大小为32，模型训练时能够并行处理批数据，因此batch_size越大，训练的效率越高，但是同时带来了内存的负荷，过大的batch_size可能导致内存不足而无法训练，因此选择一个合适的batch_size是很重要的一步；\n",
    "\n",
    "* `log_interval`：每隔10 step打印一次训练日志；\n",
    "\n",
    "* `eval_interval`：每隔50 step在验证集上进行一次性能评估；\n",
    "\n",
    "* `checkpoint_dir`：将训练的参数和数据保存到cv_finetune_turtorial_demo目录中；\n",
    "\n",
    "* `strategy`：使用DefaultFinetuneStrategy策略进行finetune；\n",
    "\n",
    "更多运行配置，请查看[RunConfig](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-RunConfig)\n",
    "\n",
    "同时PaddleHub提供了许多优化策略，如`AdamWeightDecayStrategy`、`ULMFiTStrategy`、`DefaultFinetuneStrategy`等，详细信息参见[策略](https://github.com/PaddlePaddle/PaddleHub/wiki/PaddleHub-API:-Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-04-27 00:11:16,974] [    INFO] - Checkpoint dir: cv_finetune_turtorial_demo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = hub.RunConfig(\n",
    "    use_cuda=True,                              #是否使用GPU训练，默认为False；\n",
    "    num_epoch=6,                                #Fine-tune的轮数；\n",
    "    checkpoint_dir=\"cv_finetune_turtorial_demo\",#模型checkpoint保存路径, 若用户没有指定，程序会自动生成；\n",
    "    batch_size=8,                              #训练的批大小，如果使用GPU，请根据实际情况调整batch_size；\n",
    "    eval_interval=30,                           #模型评估的间隔，默认每100个step评估一次验证集；\n",
    "    strategy=hub.finetune.strategy.DefaultFinetuneStrategy())  #Fine-tune优化策略；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6、组建Finetune Task\n",
    "有了合适的预训练模型和准备要迁移的数据集后，我们开始组建一个Task。\n",
    "\n",
    "由于该数据设置是一个二分类的任务，而我们下载的分类module是在ImageNet数据集上训练的千分类模型，所以我们需要对模型进行简单的微调，把模型改造为一个二分类模型：\n",
    "\n",
    "1. 获取module的上下文环境，包括输入和输出的变量，以及Paddle Program；\n",
    "2. 从输出变量中找到特征图提取层feature_map；\n",
    "3. 在feature_map后面接入一个全连接层，生成Task；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-04-27 00:11:18,619] [    INFO] - 267 pretrained paramaters loaded by PaddleHub\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dict, output_dict, program = module.context(trainable=True)\n",
    "img = input_dict[\"image\"]\n",
    "feature_map = output_dict[\"feature_map\"]\n",
    "feed_list = [img.name]\n",
    "\n",
    "task = hub.ImageClassifierTask(\n",
    "    data_reader=data_reader,\n",
    "    feed_list=feed_list,\n",
    "    feature=feature_map,\n",
    "    num_classes=dataset.num_labels,\n",
    "    config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5、开始Finetune\n",
    "\n",
    "我们选择`finetune_and_eval`接口来进行模型训练，这个接口在finetune的过程中，会周期性的进行模型效果的评估，以便我们了解整个训练过程的性能变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-04-27 00:11:26,920] [    INFO] - Strategy with slanted triangle learning rate, L2 regularization, \u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:26,955] [    INFO] - Try loading checkpoint from cv_finetune_turtorial_demo/ckpt.meta\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:26,956] [    INFO] - PaddleHub model checkpoint not found, start from scratch...\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:27,001] [    INFO] - PaddleHub finetune start\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:27,925] [   TRAIN] - step 10 / 1012: loss=1.57031 acc=0.25000 [step/sec: 11.75]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:28,715] [   TRAIN] - step 20 / 1012: loss=1.17109 acc=0.58750 [step/sec: 15.70]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:29,350] [   TRAIN] - step 30 / 1012: loss=0.81941 acc=0.71250 [step/sec: 16.45]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:29,352] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "share_vars_from is set, scope is ignored.\n",
      "\u001b[34m[2020-04-27 00:11:31,300] [    EVAL] - [dev dataset evaluation result] loss=1.61561 acc=0.44737 [step/sec: 13.50]\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:31,302] [    EVAL] - best model saved to cv_finetune_turtorial_demo/best_model [best acc=0.44737]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:32,656] [   TRAIN] - step 40 / 1012: loss=0.68902 acc=0.78750 [step/sec: 23.52]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:33,070] [   TRAIN] - step 50 / 1012: loss=0.55025 acc=0.83750 [step/sec: 24.36]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:33,474] [   TRAIN] - step 60 / 1012: loss=0.61470 acc=0.80000 [step/sec: 24.93]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:33,476] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:34,967] [    EVAL] - [dev dataset evaluation result] loss=2.29334 acc=0.38816 [step/sec: 13.56]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:35,378] [   TRAIN] - step 70 / 1012: loss=0.41283 acc=0.83750 [step/sec: 24.47]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:35,786] [   TRAIN] - step 80 / 1012: loss=0.47417 acc=0.87500 [step/sec: 24.66]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:36,194] [   TRAIN] - step 90 / 1012: loss=0.19238 acc=0.96250 [step/sec: 24.72]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:36,195] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:37,684] [    EVAL] - [dev dataset evaluation result] loss=1.56139 acc=0.44737 [step/sec: 13.56]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:38,131] [   TRAIN] - step 100 / 1012: loss=0.25913 acc=0.88750 [step/sec: 24.52]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:38,538] [   TRAIN] - step 110 / 1012: loss=0.39848 acc=0.88750 [step/sec: 24.71]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:38,955] [   TRAIN] - step 120 / 1012: loss=0.29049 acc=0.86250 [step/sec: 24.12]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:38,956] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:40,368] [    EVAL] - [dev dataset evaluation result] loss=1.09691 acc=0.63158 [step/sec: 14.60]\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:40,370] [    EVAL] - best model saved to cv_finetune_turtorial_demo/best_model [best acc=0.63158]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:42,311] [   TRAIN] - step 130 / 1012: loss=0.23860 acc=0.95000 [step/sec: 23.73]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:42,747] [   TRAIN] - step 140 / 1012: loss=0.15003 acc=0.97500 [step/sec: 23.22]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:43,174] [   TRAIN] - step 150 / 1012: loss=0.11630 acc=0.96250 [step/sec: 23.65]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:43,176] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:44,598] [    EVAL] - [dev dataset evaluation result] loss=1.32903 acc=0.54167 [step/sec: 14.21]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:45,025] [   TRAIN] - step 160 / 1012: loss=0.11372 acc=1.00000 [step/sec: 23.69]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:45,506] [   TRAIN] - step 170 / 1012: loss=0.16205 acc=0.87500 [step/sec: 25.25]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:46,190] [   TRAIN] - step 180 / 1012: loss=0.07234 acc=0.98750 [step/sec: 15.04]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:46,191] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:47,665] [    EVAL] - [dev dataset evaluation result] loss=0.74103 acc=0.67544 [step/sec: 13.70]\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:47,667] [    EVAL] - best model saved to cv_finetune_turtorial_demo/best_model [best acc=0.67544]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:49,129] [   TRAIN] - step 190 / 1012: loss=0.16357 acc=0.93750 [step/sec: 24.70]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:49,538] [   TRAIN] - step 200 / 1012: loss=0.11934 acc=0.96250 [step/sec: 24.63]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:49,940] [   TRAIN] - step 210 / 1012: loss=0.17318 acc=0.90000 [step/sec: 25.01]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:49,941] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:51,384] [    EVAL] - [dev dataset evaluation result] loss=1.98443 acc=0.51754 [step/sec: 14.04]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:51,789] [   TRAIN] - step 220 / 1012: loss=0.18134 acc=0.95000 [step/sec: 24.87]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:52,193] [   TRAIN] - step 230 / 1012: loss=0.24961 acc=0.93750 [step/sec: 24.90]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:52,595] [   TRAIN] - step 240 / 1012: loss=0.15735 acc=0.96250 [step/sec: 25.14]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:52,596] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:54,082] [    EVAL] - [dev dataset evaluation result] loss=1.89215 acc=0.54167 [step/sec: 13.97]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:54,481] [   TRAIN] - step 250 / 1012: loss=0.22255 acc=0.91250 [step/sec: 25.25]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:54,882] [   TRAIN] - step 260 / 1012: loss=0.11959 acc=0.95000 [step/sec: 25.04]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:55,285] [   TRAIN] - step 270 / 1012: loss=0.18841 acc=0.92500 [step/sec: 24.94]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:55,286] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:56,686] [    EVAL] - [dev dataset evaluation result] loss=1.45598 acc=0.54605 [step/sec: 14.51]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:57,111] [   TRAIN] - step 280 / 1012: loss=0.18657 acc=0.93750 [step/sec: 23.65]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:57,539] [   TRAIN] - step 290 / 1012: loss=0.27942 acc=0.91250 [step/sec: 23.68]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:57,962] [   TRAIN] - step 300 / 1012: loss=0.30018 acc=0.87500 [step/sec: 23.91]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:11:57,964] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:11:59,354] [    EVAL] - [dev dataset evaluation result] loss=1.03365 acc=0.63377 [step/sec: 14.59]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:11:59,757] [   TRAIN] - step 310 / 1012: loss=0.15519 acc=0.95000 [step/sec: 24.90]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:00,166] [   TRAIN] - step 320 / 1012: loss=0.18618 acc=0.92500 [step/sec: 24.63]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:00,576] [   TRAIN] - step 330 / 1012: loss=0.12765 acc=0.98750 [step/sec: 24.53]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:00,577] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:02,005] [    EVAL] - [dev dataset evaluation result] loss=1.92513 acc=0.51316 [step/sec: 14.15]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:02,537] [   TRAIN] - step 340 / 1012: loss=0.04144 acc=1.00000 [step/sec: 16.97]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:03,157] [   TRAIN] - step 350 / 1012: loss=0.32661 acc=0.92500 [step/sec: 16.31]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:03,897] [   TRAIN] - step 360 / 1012: loss=0.06453 acc=0.97500 [step/sec: 13.90]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:03,898] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:05,284] [    EVAL] - [dev dataset evaluation result] loss=2.39681 acc=0.55482 [step/sec: 14.62]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:05,700] [   TRAIN] - step 370 / 1012: loss=0.10749 acc=0.96250 [step/sec: 24.16]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:06,110] [   TRAIN] - step 380 / 1012: loss=0.08217 acc=0.97500 [step/sec: 24.57]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:06,535] [   TRAIN] - step 390 / 1012: loss=0.07915 acc=0.97500 [step/sec: 23.91]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:06,536] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:08,070] [    EVAL] - [dev dataset evaluation result] loss=1.92384 acc=0.57237 [step/sec: 13.07]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:08,478] [   TRAIN] - step 400 / 1012: loss=0.07059 acc=0.97500 [step/sec: 24.83]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:08,922] [   TRAIN] - step 410 / 1012: loss=0.03359 acc=0.98750 [step/sec: 22.62]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:09,335] [   TRAIN] - step 420 / 1012: loss=0.08143 acc=0.98750 [step/sec: 24.39]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:09,336] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:10,829] [    EVAL] - [dev dataset evaluation result] loss=1.62594 acc=0.55921 [step/sec: 13.58]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:11,263] [   TRAIN] - step 430 / 1012: loss=0.06652 acc=0.96250 [step/sec: 23.20]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:11,700] [   TRAIN] - step 440 / 1012: loss=0.04617 acc=1.00000 [step/sec: 23.13]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:12,128] [   TRAIN] - step 450 / 1012: loss=0.11578 acc=0.96250 [step/sec: 23.46]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:12,130] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:13,520] [    EVAL] - [dev dataset evaluation result] loss=1.32517 acc=0.60965 [step/sec: 14.56]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:13,966] [   TRAIN] - step 460 / 1012: loss=0.07699 acc=0.98750 [step/sec: 22.55]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:14,412] [   TRAIN] - step 470 / 1012: loss=0.06550 acc=0.98750 [step/sec: 22.72]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:14,863] [   TRAIN] - step 480 / 1012: loss=0.09186 acc=0.97500 [step/sec: 22.41]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:14,864] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:16,209] [    EVAL] - [dev dataset evaluation result] loss=1.04763 acc=0.71491 [step/sec: 15.08]\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:16,210] [    EVAL] - best model saved to cv_finetune_turtorial_demo/best_model [best acc=0.71491]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:17,574] [   TRAIN] - step 490 / 1012: loss=0.08335 acc=1.00000 [step/sec: 22.33]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:18,002] [   TRAIN] - step 500 / 1012: loss=0.01820 acc=1.00000 [step/sec: 23.60]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:18,639] [   TRAIN] - step 510 / 1012: loss=0.06151 acc=0.95833 [step/sec: 11.02]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:18,641] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:20,060] [    EVAL] - [dev dataset evaluation result] loss=1.59171 acc=0.66228 [step/sec: 14.54]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:20,470] [   TRAIN] - step 520 / 1012: loss=0.07314 acc=0.97500 [step/sec: 24.53]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:20,889] [   TRAIN] - step 530 / 1012: loss=0.04480 acc=0.98750 [step/sec: 24.04]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:21,328] [   TRAIN] - step 540 / 1012: loss=0.05959 acc=0.96250 [step/sec: 22.87]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:21,329] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:22,838] [    EVAL] - [dev dataset evaluation result] loss=1.55149 acc=0.52632 [step/sec: 13.31]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:23,245] [   TRAIN] - step 550 / 1012: loss=0.02960 acc=1.00000 [step/sec: 24.70]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:23,654] [   TRAIN] - step 560 / 1012: loss=0.20939 acc=0.92500 [step/sec: 24.60]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:24,059] [   TRAIN] - step 570 / 1012: loss=0.08011 acc=0.97500 [step/sec: 24.82]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:24,060] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:25,675] [    EVAL] - [dev dataset evaluation result] loss=0.89340 acc=0.63816 [step/sec: 12.63]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:26,091] [   TRAIN] - step 580 / 1012: loss=0.03026 acc=1.00000 [step/sec: 24.17]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:26,540] [   TRAIN] - step 590 / 1012: loss=0.02830 acc=1.00000 [step/sec: 22.37]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:26,948] [   TRAIN] - step 600 / 1012: loss=0.19110 acc=0.93750 [step/sec: 24.64]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:26,949] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:28,320] [    EVAL] - [dev dataset evaluation result] loss=1.24752 acc=0.59868 [step/sec: 14.74]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:28,730] [   TRAIN] - step 610 / 1012: loss=0.05487 acc=0.98750 [step/sec: 24.57]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:29,131] [   TRAIN] - step 620 / 1012: loss=0.09332 acc=0.96250 [step/sec: 25.23]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:29,551] [   TRAIN] - step 630 / 1012: loss=0.10944 acc=0.97500 [step/sec: 23.91]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:29,552] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:30,915] [    EVAL] - [dev dataset evaluation result] loss=1.23694 acc=0.61184 [step/sec: 14.82]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:31,358] [   TRAIN] - step 640 / 1012: loss=0.04928 acc=0.98750 [step/sec: 22.81]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:31,814] [   TRAIN] - step 650 / 1012: loss=0.07864 acc=0.96250 [step/sec: 22.16]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:32,258] [   TRAIN] - step 660 / 1012: loss=0.03391 acc=1.00000 [step/sec: 22.73]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:32,259] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:33,619] [    EVAL] - [dev dataset evaluation result] loss=2.35559 acc=0.51096 [step/sec: 14.92]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:34,048] [   TRAIN] - step 670 / 1012: loss=0.19607 acc=0.96250 [step/sec: 23.59]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:34,613] [   TRAIN] - step 680 / 1012: loss=0.03046 acc=1.00000 [step/sec: 17.32]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:35,644] [   TRAIN] - step 690 / 1012: loss=0.07276 acc=0.97500 [step/sec: 10.18]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:35,645] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:37,036] [    EVAL] - [dev dataset evaluation result] loss=1.67047 acc=0.60526 [step/sec: 14.52]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:37,475] [   TRAIN] - step 700 / 1012: loss=0.07862 acc=0.97500 [step/sec: 22.95]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:37,897] [   TRAIN] - step 710 / 1012: loss=0.14069 acc=0.95000 [step/sec: 23.86]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:38,326] [   TRAIN] - step 720 / 1012: loss=0.03274 acc=0.98750 [step/sec: 23.44]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:38,328] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:39,791] [    EVAL] - [dev dataset evaluation result] loss=1.85835 acc=0.51096 [step/sec: 13.82]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:40,227] [   TRAIN] - step 730 / 1012: loss=0.23055 acc=0.92500 [step/sec: 23.12]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:40,630] [   TRAIN] - step 740 / 1012: loss=0.12003 acc=0.97500 [step/sec: 24.94]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:41,041] [   TRAIN] - step 750 / 1012: loss=0.15536 acc=0.95000 [step/sec: 24.50]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:41,043] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:42,527] [    EVAL] - [dev dataset evaluation result] loss=1.43486 acc=0.60746 [step/sec: 13.57]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:42,950] [   TRAIN] - step 760 / 1012: loss=0.06246 acc=0.98750 [step/sec: 23.78]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:43,405] [   TRAIN] - step 770 / 1012: loss=0.08975 acc=0.97500 [step/sec: 22.23]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:43,836] [   TRAIN] - step 780 / 1012: loss=0.14719 acc=0.95000 [step/sec: 23.33]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:43,837] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:45,260] [    EVAL] - [dev dataset evaluation result] loss=2.57905 acc=0.65132 [step/sec: 14.22]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:45,730] [   TRAIN] - step 790 / 1012: loss=0.07191 acc=0.98750 [step/sec: 21.38]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:46,185] [   TRAIN] - step 800 / 1012: loss=0.16084 acc=0.92500 [step/sec: 22.18]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:46,634] [   TRAIN] - step 810 / 1012: loss=0.02336 acc=1.00000 [step/sec: 22.57]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:46,635] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:48,097] [    EVAL] - [dev dataset evaluation result] loss=1.07534 acc=0.59649 [step/sec: 13.79]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:48,529] [   TRAIN] - step 820 / 1012: loss=0.06362 acc=0.97500 [step/sec: 23.40]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:48,956] [   TRAIN] - step 830 / 1012: loss=0.15132 acc=0.96250 [step/sec: 23.65]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:49,387] [   TRAIN] - step 840 / 1012: loss=0.23706 acc=0.96250 [step/sec: 23.43]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:49,388] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:50,737] [    EVAL] - [dev dataset evaluation result] loss=0.98084 acc=0.61404 [step/sec: 15.00]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:51,370] [   TRAIN] - step 850 / 1012: loss=0.16023 acc=0.95000 [step/sec: 14.58]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:52,194] [   TRAIN] - step 860 / 1012: loss=0.14728 acc=0.95000 [step/sec: 12.82]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:52,855] [   TRAIN] - step 870 / 1012: loss=0.10386 acc=0.96250 [step/sec: 15.79]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:52,857] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:54,389] [    EVAL] - [dev dataset evaluation result] loss=0.86016 acc=0.72588 [step/sec: 13.38]\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:54,390] [    EVAL] - best model saved to cv_finetune_turtorial_demo/best_model [best acc=0.72588]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:55,832] [   TRAIN] - step 880 / 1012: loss=0.05542 acc=0.98750 [step/sec: 24.25]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:56,244] [   TRAIN] - step 890 / 1012: loss=0.08049 acc=0.98750 [step/sec: 24.43]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:56,665] [   TRAIN] - step 900 / 1012: loss=0.16598 acc=0.97500 [step/sec: 23.89]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:56,667] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:12:58,133] [    EVAL] - [dev dataset evaluation result] loss=0.89903 acc=0.69956 [step/sec: 13.84]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:58,564] [   TRAIN] - step 910 / 1012: loss=0.06727 acc=0.97500 [step/sec: 23.28]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:58,998] [   TRAIN] - step 920 / 1012: loss=0.02842 acc=1.00000 [step/sec: 23.19]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:12:59,423] [   TRAIN] - step 930 / 1012: loss=0.05566 acc=0.97500 [step/sec: 23.71]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:12:59,424] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:13:00,912] [    EVAL] - [dev dataset evaluation result] loss=0.73658 acc=0.71930 [step/sec: 13.85]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:01,340] [   TRAIN] - step 940 / 1012: loss=0.05036 acc=0.97500 [step/sec: 23.46]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:01,756] [   TRAIN] - step 950 / 1012: loss=0.07952 acc=0.97500 [step/sec: 24.18]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:02,162] [   TRAIN] - step 960 / 1012: loss=0.10206 acc=0.97500 [step/sec: 24.76]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:02,163] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:13:03,643] [    EVAL] - [dev dataset evaluation result] loss=0.81243 acc=0.62061 [step/sec: 13.64]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:04,064] [   TRAIN] - step 970 / 1012: loss=0.05185 acc=0.98750 [step/sec: 23.86]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:04,489] [   TRAIN] - step 980 / 1012: loss=0.03390 acc=1.00000 [step/sec: 23.81]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:04,925] [   TRAIN] - step 990 / 1012: loss=0.04586 acc=0.98750 [step/sec: 23.15]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:04,927] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:13:06,328] [    EVAL] - [dev dataset evaluation result] loss=0.90379 acc=0.67105 [step/sec: 14.42]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:06,761] [   TRAIN] - step 1000 / 1012: loss=0.06048 acc=0.96250 [step/sec: 23.33]\u001b[0m\n",
      "\u001b[36m[2020-04-27 00:13:07,190] [   TRAIN] - step 1010 / 1012: loss=0.02933 acc=1.00000 [step/sec: 23.57]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:07,351] [    INFO] - Evaluation on dev dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:13:08,770] [    EVAL] - [dev dataset evaluation result] loss=1.01474 acc=0.62061 [step/sec: 14.26]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:08,771] [    INFO] - Load the best model from cv_finetune_turtorial_demo/best_model\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:09,057] [    INFO] - Evaluation on test dataset start\u001b[0m\n",
      "\u001b[34m[2020-04-27 00:13:09,345] [    EVAL] - [test dataset evaluation result] loss=0.48384 acc=0.80000 [step/sec: 90.35]\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:09,346] [    INFO] - Saving model checkpoint to cv_finetune_turtorial_demo/step_1014\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:10,417] [    INFO] - PaddleHub finetune finished.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run_states = task.finetune_and_eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6、预测\n",
    "\n",
    "当Finetune完成后，我们使用模型来进行预测，先通过以下命令来获取测试的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2020-04-27 00:13:18,901] [    INFO] - PaddleHub predict start\u001b[0m\n",
      "\u001b[32m[2020-04-27 00:13:18,902] [    INFO] - The best model has been loaded\u001b[0m\n",
      "share_vars_from is set, scope is ignored.\n",
      "\u001b[32m[2020-04-27 00:13:19,246] [    INFO] - PaddleHub predict finished.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.0557995e-01, 9.4774441e-05, 6.8352532e-01, 1.0028933e-04,\n",
      "        2.1069965e-01],\n",
      "       [1.3865610e-02, 9.7437876e-01, 6.3070317e-04, 7.4425531e-03,\n",
      "        3.6823847e-03],\n",
      "       [2.7508082e-02, 4.4674138e-04, 9.7096866e-01, 4.4555618e-05,\n",
      "        1.0319104e-03],\n",
      "       [2.8014809e-03, 9.7184954e-03, 8.9868620e-02, 8.9628881e-01,\n",
      "        1.3226331e-03],\n",
      "       [2.0428139e-03, 1.4909144e-03, 2.1174692e-03, 3.2001277e-04,\n",
      "        9.9402881e-01]], dtype=float32)]\n",
      "[2 1 2 3 4]\n",
      "input 1 is dataset/test/anqi.jpg, and the predict result is 许佳琪\n",
      "input 2 is dataset/test/wangchengxuan.jpg, and the predict result is 王承渲\n",
      "input 3 is dataset/test/xujiaqi.jpg, and the predict result is 许佳琪\n",
      "input 4 is dataset/test/yushuxin.jpg, and the predict result is 虞书欣\n",
      "input 5 is dataset/test/zhaoxiaotang.jpg, and the predict result is 赵小棠\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "with open(\"dataset/test_list.txt\",\"r\") as f:\n",
    "    filepath = f.readlines()\n",
    "\n",
    "data = [filepath[0].split(\" \")[0],filepath[1].split(\" \")[0],filepath[2].split(\" \")[0],filepath[3].split(\" \")[0],filepath[4].split(\" \")[0]]\n",
    "\n",
    "label_map = dataset.label_dict()\n",
    "index = 0\n",
    "run_states = task.predict(data=data)\n",
    "results = [run_state.run_results for run_state in run_states]\n",
    "\n",
    "for batch_result in results:\n",
    "    print(batch_result)\n",
    "    batch_result = np.argmax(batch_result, axis=2)[0]\n",
    "    print(batch_result)\n",
    "    for result in batch_result:\n",
    "        index += 1\n",
    "        result = label_map[result]\n",
    "        print(\"input %i is %s, and the predict result is %s\" %\n",
    "              (index, data[index - 1], result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.1 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
